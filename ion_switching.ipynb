{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     119
    ]
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from functools import partial\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "def MacroF1MetricRegression(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = np.round(np.clip(preds, 0, 10)).astype(np.int16)\n",
    "    score = f1_score(labels, preds, average='macro')\n",
    "    return ('MacroF1Metric', score, True)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2  # just added\n",
    "    for col in tqdm(df.columns):\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(\n",
    "                        np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(\n",
    "                        np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(\n",
    "                        np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(\n",
    "                        np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(\n",
    "                        np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(\n",
    "                        np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    percent = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(\n",
    "        'Mem. usage decreased from {:5.2f} Mb to {:5.2f} Mb ({:.1f}% reduction)'\n",
    "        .format(start_mem, end_mem, percent))\n",
    "    return df\n",
    "\n",
    "\n",
    "class OptimizedRounder(object):\n",
    "    \"\"\"\n",
    "    An optimizer for rounding thresholds\n",
    "    to maximize F1 (Macro) score\n",
    "    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "\n",
    "    def _f1_loss(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        Get loss according to\n",
    "        using current coefficients\n",
    "\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf],\n",
    "                     labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "        return -f1_score(y, X_p, average='macro')\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Optimize rounding thresholds\n",
    "\n",
    "        :param X: The raw predictions\n",
    "        :param y: The ground truth labels\n",
    "        \"\"\"\n",
    "        loss_partial = partial(self._f1_loss, X=X, y=y)\n",
    "        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "        print(\"Optimizing rounder...\")\n",
    "        self.coef_ = sp.optimize.minimize(loss_partial,\n",
    "                                          initial_coef,\n",
    "                                          method='nelder-mead')\n",
    "\n",
    "    def predict(self, X, coef):\n",
    "        \"\"\"\n",
    "        Make predictions with specified thresholds\n",
    "\n",
    "        :param X: The raw predictions\n",
    "        :param coef: A list of coefficients that will be used for rounding\n",
    "        \"\"\"\n",
    "        print(\"Rounding...\")\n",
    "        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf],\n",
    "                      labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "    def coefficients(self):\n",
    "        \"\"\"\n",
    "        Return the optimized coefficients\n",
    "        \"\"\"\n",
    "        return self.coef_['x']\n",
    "\n",
    "\n",
    "def train_lgb(params: dict,\n",
    "              X,\n",
    "              y,\n",
    "              X_test,\n",
    "              oof_df,\n",
    "              features,\n",
    "              feval: dict = {},\n",
    "              objective: str = 'regression',\n",
    "              num_boost_round: int = 1,\n",
    "              early_stopping_rounds: int = 50,\n",
    "              verbose=10):\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    feat_importance_df = pd.DataFrame(index=features)\n",
    "    fold = 0\n",
    "    f1 = []\n",
    "    for train_id, valid_id in tqdm(kfold.split(X, y)):\n",
    "        fold += 1\n",
    "        x_train, y_train = X.iloc[train_id, :], y.iloc[train_id]\n",
    "        x_val, y_val = X.iloc[valid_id, :], y.iloc[valid_id]\n",
    "\n",
    "        train_set = lgb.Dataset(x_train, y_train)\n",
    "        valid_set = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "        model = lgb.train(params=params,\n",
    "                          feval=feval[objective],\n",
    "                          train_set=train_set,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          early_stopping_rounds=early_stopping_rounds,\n",
    "                          valid_sets=[train_set, valid_set],\n",
    "                          verbose_eval=verbose)\n",
    "        pred = model.predict(x_val, num_iteration=model.best_iteration)\n",
    "\n",
    "        pred = np.round(np.clip(pred, 0, 10)).astype(np.int32)\n",
    "\n",
    "        test_preds = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "        test_preds = np.round(np.clip(test_preds, 0, 10)).astype(np.int32)\n",
    "\n",
    "        oof_df.loc[oof_df.iloc[valid_id].index, 'oof'] = pred\n",
    "        sub[f'lgb_open_channels_fold_{fold}'] = test_preds\n",
    "\n",
    "        f1.append(\n",
    "            f1_score(oof_df.loc[oof_df.iloc[valid_id].index]['open_channels'],\n",
    "                     oof_df.loc[oof_df.iloc[valid_id].index]['oof'],\n",
    "                     average='macro'))\n",
    "        rmse = np.sqrt(\n",
    "            mean_squared_error(\n",
    "                oof_df.loc[oof_df.index.isin(valid_id)]['open_channels'],\n",
    "                oof_df.loc[oof_df.index.isin(valid_id)]['oof']))\n",
    "        feat_importance_df[\n",
    "            f'lgb_importance_{fold}'] = model.feature_importance()\n",
    "\n",
    "    print(f\"Mean oof f1:{np.mean(f1)}, std: {np.std(f1)}\")\n",
    "\n",
    "    oof_f1 = f1_score(oof_df['open_channels'], oof_df['oof'], average='macro')\n",
    "    oof_rmse = np.sqrt(\n",
    "        mean_squared_error(oof_df['open_channels'], oof_df['oof']))\n",
    "\n",
    "    return oof_df.copy(), feat_importance_df.copy(), sub.copy(\n",
    "    ), oof_f1, oof_rmse\n",
    "\n",
    "\n",
    "def train_xgb(params: dict,\n",
    "              X,\n",
    "              y,\n",
    "              X_test,\n",
    "              oof_df,\n",
    "              features,\n",
    "              feval: dict = {},\n",
    "              verbose_eval=100,\n",
    "              objective: str = 'regression',\n",
    "              num_boost_round: int = 1,\n",
    "              early_stopping_rounds: int = 50,\n",
    "              sklearn_model=None):\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    feat_importance_df = pd.DataFrame(index=features)\n",
    "    fold = 0\n",
    "    f1 = []\n",
    "    for train_id, valid_id in kfold.split(X, y):\n",
    "        fold += 1\n",
    "        x_train, y_train = X.iloc[train_id, :], y.iloc[train_id]\n",
    "        x_val, y_val = X.iloc[valid_id, :], y.iloc[valid_id]\n",
    "\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        valid_set = xgb.DMatrix(x_val, y_val)\n",
    "\n",
    "        model = xgb.train(params,\n",
    "                          train_set,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          evals=[(train_set, 'train'), (valid_set, 'val')],\n",
    "                          feval=feval[objective],\n",
    "                          verbose_eval=verbose_eval,\n",
    "                          maximize=True,\n",
    "                          early_stopping_rounds=early_stopping_rounds)\n",
    "        pred = model.predict(xgb.DMatrix(x_val))\n",
    "        pred = np.round(np.clip(pred, 0, 10)).astype(np.int32)\n",
    "\n",
    "        test_preds = model.predict(xgb.DMatrix(X_test))\n",
    "        test_preds = np.round(np.clip(test_preds, 0, 10)).astype(np.int32)\n",
    "\n",
    "        oof_df.loc[oof_df.iloc[valid_id].index, 'oof'] = pred\n",
    "        sub[f'{model_type}_open_channels_fold_{fold}'] = test_preds\n",
    "\n",
    "        f1 = f1_score(oof_df.loc[oof_df.iloc[valid_id].index]['open_channels'],\n",
    "                      oof_df.loc[oof_df.iloc[valid_id].index]['oof'],\n",
    "                      average='macro')\n",
    "        f1.append(\n",
    "            f1_score(oof_df.loc[oof_df.iloc[valid_id].index]['open_channels'],\n",
    "                     oof_df.loc[oof_df.iloc[valid_id].index]['oof'],\n",
    "                     average='macro'))\n",
    "        rmse = np.sqrt(\n",
    "            mean_squared_error(\n",
    "                oof_df.loc[oof_df.index.isin(valid_id)]['open_channels'],\n",
    "                oof_df.loc[oof_df.index.isin(valid_id)]['oof']))\n",
    "\n",
    "    oof_f1 = f1_score(oof_df['open_channels'], oof_df['oof'], average='macro')\n",
    "    oof_rmse = np.sqrt(\n",
    "        mean_squared_error(oof_df['open_channels'], oof_df['oof']))\n",
    "    \n",
    "    print(f\"Mean oof f1:{np.mean(f1)}, std: {np.std(f1)}\")\n",
    "    return oof_df.copy(), feat_importance_df.copy(), sub.copy(\n",
    "    ), oof_f1, oof_rmse\n",
    "\n",
    "\n",
    "feval = {\n",
    "    # 'classification': MacroF1MetricClassification,\n",
    "    'regression': MacroF1MetricRegression\n",
    "}\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('liverpool-ion-switching/train.csv',\n",
    "                    dtype={\n",
    "                        'time': np.float32,\n",
    "                        'signal': np.float32,\n",
    "                        'open_channels': np.int32\n",
    "                    })\n",
    "test = pd.read_csv('liverpool-ion-switching/test.csv',\n",
    "                    dtype={\n",
    "                        'time': np.float32,\n",
    "                        'signal': np.float32,\n",
    "                    })\n",
    "sub = pd.read_csv('liverpool-ion-switching/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(df: pd.DataFrame, bs=500_000, bs_slice=25_000, windows=(10, 50)):\n",
    "    df = df.sort_values(by=['time']).reset_index(drop=True)\n",
    "    df.index = ((df.time * 10_000) - 1).values\n",
    "    df['batch'] = df.index // bs\n",
    "    df['batch_index'] = df.index - (df.batch * bs)\n",
    "    df['batch_slices'] = df['batch_index'] // bs_slice\n",
    "    df['batch_slices2'] = df['batch'].astype(str).str.zfill(\n",
    "        3) + '_' + df['batch_slices'].astype(str).str.zfill(3)\n",
    "\n",
    "    for c in tqdm(['batch', 'batch_slices2']):\n",
    "        df[f'batch_{bs//1000}k_max_{c}'] = df.groupby(\n",
    "            [f'{c}'])['signal_undrifted'].transform(np.max)\n",
    "        df[f'batch_{bs//1000}k_min_{c}'] = df.groupby(\n",
    "            [f'{c}'])['signal_undrifted'].transform(np.min)\n",
    "        df[f'batch_{bs//1000}k_mean_{c}'] = df.groupby(\n",
    "            [f'{c}'])['signal_undrifted'].transform(np.mean)\n",
    "        df[f'batch_{bs//1000}k_std_{c}'] = df.groupby(\n",
    "            [f'{c}'])['signal_undrifted'].transform(np.std)\n",
    "        df[f'batch_{bs//1000}k_median_{c}'] = df.groupby(\n",
    "            [f'{c}'])['signal_undrifted'].transform(np.median)\n",
    "        df[f'batch_{bs//1000}k_diff_max_{c}'] = df.groupby([\n",
    "            f'{c}'\n",
    "        ])['signal_undrifted'].transform(lambda x: np.max(np.diff(x)))\n",
    "\n",
    "        df[f'batch_{bs//1000}k_diff_min_{c}'] = df.groupby([\n",
    "            f'{c}'\n",
    "        ])['signal_undrifted'].transform(lambda x: np.min(np.diff(x)))\n",
    "        df[f'batch_{bs//1000}k_range_{c}'] = np.abs(\n",
    "            df[f'batch_{bs//1000}k_max_{c}'] -\n",
    "            df[f'batch_{bs//1000}k_min_{c}'])\n",
    "        df[f'batch_{bs//1000}k_maxtomin_{c}'] = np.abs(\n",
    "            (df[f'batch_{bs//1000}k_max_{c}'] + 1e-10) /\n",
    "            (df[f'batch_{bs//1000}k_min_{c}'] + 1e-10))\n",
    "\n",
    "        df[f'batch_{bs//1000}k_shift_1_{c}'] = df.groupby(\n",
    "            [f'{c}']).shift(1)['signal_undrifted']\n",
    "        df[f'batch_{bs//1000}k_shift_-1_{c}'] = df.groupby(\n",
    "            [f'{c}']).shift(-1)['signal_undrifted']\n",
    "        df[f'batch_{bs//1000}k_shift_2_{c}'] = df.groupby(\n",
    "            [f'{c}']).shift(2)['signal_undrifted']\n",
    "        df[f'batch_{bs//1000}k_shift_-2_{c}'] = df.groupby(\n",
    "            [f'{c}']).shift(-2)['signal_undrifted']\n",
    "        for window in tqdm(windows):\n",
    "            df[f'batch_{bs//1000}k_rolling_max_{c}_{window}'] = df[\n",
    "                'signal_undrifted'].rolling(window=window).max()\n",
    "            df[f'batch_{bs//1000}k_rolling_min_{c}_{window}'] = df[\n",
    "                'signal_undrifted'].rolling(window=window).min()\n",
    "            df[f'batch_{bs//1000}k_rolling_maxtomin_{c}_{window}'] = (\n",
    "                df[f'batch_{bs//1000}k_rolling_max_{c}_{window}'] + 1e-10) / (\n",
    "                    df[f'batch_{bs//1000}k_rolling_min_{c}_{window}'] + 1e-10)\n",
    "            df[f'batch_{bs//1000}k_rolling_range_{c}_{window}'] = df[\n",
    "                f'batch_{bs//1000}k_rolling_max_{c}_{window}'] - df[\n",
    "                    f'batch_{bs//1000}k_rolling_min_{c}_{window}']\n",
    "\n",
    "            df[f'batch_{bs//1000}k_rolling_mean_{c}_{window}'] = df[\n",
    "                'signal_undrifted'].rolling(window=window).mean()\n",
    "            df[f'batch_{bs//1000}k_rolling_std_{c}_{window}'] = df[\n",
    "                'signal_undrifted'].rolling(window=window).std()\n",
    "\n",
    "    feats = [\n",
    "        c for c in df.columns if c not in [\n",
    "            'time', 'open_channels', 'batch', 'batch_index', 'batch_slices',\n",
    "            'batch_slices2'\n",
    "        ]\n",
    "    ]\n",
    "    for c in feats:\n",
    "        df[c + '_msignal'] = df[c] - df['signal_undrifted']\n",
    "    feats = [\n",
    "        c for c in df.columns if c not in [\n",
    "            'time', 'open_channels', 'batch', 'batch_index', 'batch_slices',\n",
    "            'batch_slices2'\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "    return df, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 500000\n",
    "b = 600000\n",
    "train['signal_undrifted'] = train.signal\n",
    "train.loc[train.index[a:b],\n",
    "          'signal_undrifted'] = train.signal[a:b].values - 3 * (\n",
    "              train.time.values[a:b] - 50) / 10.\n",
    "\n",
    "\n",
    "def f(x, low, high, mid):\n",
    "    return -((-low + high) / 625) * (x - mid)**2 + high - low\n",
    "\n",
    "\n",
    "# CLEAN TRAIN BATCH 7\n",
    "batch = 7\n",
    "a = 500000 * (batch - 1)\n",
    "b = 500000 * batch\n",
    "train.loc[train.index[a:b], 'signal_undrifted'] = train.signal.values[a:b] - f(\n",
    "    train.time[a:b].values, -1.817, 3.186, 325)\n",
    "# CLEAN TRAIN BATCH 8\n",
    "batch = 8\n",
    "a = 500000 * (batch - 1)\n",
    "b = 500000 * batch\n",
    "train.loc[train.index[a:b], 'signal_undrifted'] = train.signal.values[a:b] - f(\n",
    "    train.time[a:b].values, -0.094, 4.936, 375)\n",
    "# CLEAN TRAIN BATCH 9\n",
    "batch = 9\n",
    "a = 500000 * (batch - 1)\n",
    "b = 500000 * batch\n",
    "train.loc[train.index[a:b], 'signal_undrifted'] = train.signal.values[a:b] - f(\n",
    "    train.time[a:b].values, 1.715, 6.689, 425)\n",
    "# CLEAN TRAIN BATCH 10\n",
    "batch = 10\n",
    "a = 500000 * (batch - 1)\n",
    "b = 500000 * batch\n",
    "train.loc[train.index[a:b], 'signal_undrifted'] = train.signal.values[a:b] - f(\n",
    "    train.time[a:b].values, 3.361, 8.45, 475)\n",
    "\n",
    "test['signal_undrifted'] = test.signal\n",
    "\n",
    "# REMOVE BATCH 1 DRIFT\n",
    "start=500\n",
    "a = 0; b = 100000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)/10.\n",
    "start=510\n",
    "a = 100000; b = 200000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)/10.\n",
    "start=540\n",
    "a = 400000; b = 500000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)/10.\n",
    "\n",
    "# REMOVE BATCH 2 DRIFT\n",
    "start=560\n",
    "a = 600000; b = 700000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)/10.\n",
    "start=570\n",
    "a = 700000; b = 800000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)/10.\n",
    "start=580\n",
    "a = 800000; b = 900000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - 3*(test.time.values[a:b]-start)/10.\n",
    "\n",
    "# REMOVE BATCH 3 DRIFT\n",
    "def f(x):\n",
    "    return -(0.00788)*(x-625)**2+2.345 +2.58\n",
    "a = 1000000; b = 1500000\n",
    "test.loc[test.index[a:b],'signal_undrifted'] = test.signal.values[a:b] - f(test.time[a:b].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6901046d740f44dd99c21b391fe64b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb174a2c05f4729b4526f903d1a0a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4c3f27545f4e47a03d57788722201f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e395096ce24067af814f8ed8fa0474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=110.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mem. usage decreased from 3478.29 Mb to 1461.27 Mb (58.0% reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588aa51e81294390b672a0eb057dc9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae84c0388444d3dba3a65884abe2934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a538d93d3841c7896957624b02630d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cf97744a274665b75bba20758941fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=109.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mem. usage decreased from 1384.74 Mb to 568.39 Mb (59.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "train, features = feature_eng(train, bs=25_000, bs_slice=2500, windows=[10,50])\n",
    "train = reduce_mem_usage(train)\n",
    "test, _ = feature_eng(test, bs=25_000, bs_slice=2500, windows=[10,50])\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Signal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal as sps\n",
    "from numpy import fft\n",
    "import pywt\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a53adb2d0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=train['open_channels'].values, y=train['batch_50k_median_batch'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LightGBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    'learning_rate': 0.015,  #0.098\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 200,  #2**8 + 1,\n",
    "    'metric': 'rmse',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'sample_fraction': 0.33\n",
    "}\n",
    "\n",
    "X = train[features]\n",
    "X_test = test[features]\n",
    "y = train['open_channels']\n",
    "oof_df = train[['time', 'open_channels']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18003d5676554867815a2a5218327e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.610725\ttraining's MacroF1Metric: 0.339966\tvalid_1's rmse: 0.610983\tvalid_1's MacroF1Metric: 0.340484\n",
      "[200]\ttraining's rmse: 0.207942\ttraining's MacroF1Metric: 0.920234\tvalid_1's rmse: 0.208619\tvalid_1's MacroF1Metric: 0.919486\n",
      "[300]\ttraining's rmse: 0.162333\ttraining's MacroF1Metric: 0.934983\tvalid_1's rmse: 0.163312\tvalid_1's MacroF1Metric: 0.93458\n",
      "[400]\ttraining's rmse: 0.158425\ttraining's MacroF1Metric: 0.936598\tvalid_1's rmse: 0.159669\tvalid_1's MacroF1Metric: 0.936183\n",
      "[500]\ttraining's rmse: 0.157381\ttraining's MacroF1Metric: 0.937226\tvalid_1's rmse: 0.158853\tvalid_1's MacroF1Metric: 0.936848\n",
      "[600]\ttraining's rmse: 0.156822\ttraining's MacroF1Metric: 0.937691\tvalid_1's rmse: 0.158488\tvalid_1's MacroF1Metric: 0.937016\n",
      "[700]\ttraining's rmse: 0.156379\ttraining's MacroF1Metric: 0.937904\tvalid_1's rmse: 0.158267\tvalid_1's MacroF1Metric: 0.937025\n",
      "[800]\ttraining's rmse: 0.156015\ttraining's MacroF1Metric: 0.938077\tvalid_1's rmse: 0.158095\tvalid_1's MacroF1Metric: 0.937115\n",
      "[900]\ttraining's rmse: 0.155683\ttraining's MacroF1Metric: 0.938292\tvalid_1's rmse: 0.157958\tvalid_1's MacroF1Metric: 0.937204\n",
      "[1000]\ttraining's rmse: 0.155391\ttraining's MacroF1Metric: 0.938453\tvalid_1's rmse: 0.157844\tvalid_1's MacroF1Metric: 0.937205\n",
      "[1100]\ttraining's rmse: 0.155116\ttraining's MacroF1Metric: 0.938587\tvalid_1's rmse: 0.157733\tvalid_1's MacroF1Metric: 0.937292\n",
      "[1200]\ttraining's rmse: 0.154844\ttraining's MacroF1Metric: 0.938713\tvalid_1's rmse: 0.157626\tvalid_1's MacroF1Metric: 0.937305\n",
      "[1300]\ttraining's rmse: 0.154579\ttraining's MacroF1Metric: 0.938848\tvalid_1's rmse: 0.157527\tvalid_1's MacroF1Metric: 0.937367\n",
      "[1400]\ttraining's rmse: 0.154326\ttraining's MacroF1Metric: 0.938955\tvalid_1's rmse: 0.157437\tvalid_1's MacroF1Metric: 0.937432\n",
      "[1500]\ttraining's rmse: 0.154096\ttraining's MacroF1Metric: 0.939116\tvalid_1's rmse: 0.157373\tvalid_1's MacroF1Metric: 0.937466\n",
      "[1600]\ttraining's rmse: 0.153881\ttraining's MacroF1Metric: 0.939248\tvalid_1's rmse: 0.157316\tvalid_1's MacroF1Metric: 0.937478\n",
      "[1700]\ttraining's rmse: 0.153679\ttraining's MacroF1Metric: 0.939384\tvalid_1's rmse: 0.157273\tvalid_1's MacroF1Metric: 0.937469\n",
      "Early stopping, best iteration is:\n",
      "[1579]\ttraining's rmse: 0.153923\ttraining's MacroF1Metric: 0.939226\tvalid_1's rmse: 0.157327\tvalid_1's MacroF1Metric: 0.937502\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.610776\ttraining's MacroF1Metric: 0.340629\tvalid_1's rmse: 0.610758\tvalid_1's MacroF1Metric: 0.340388\n",
      "[200]\ttraining's rmse: 0.20795\ttraining's MacroF1Metric: 0.919761\tvalid_1's rmse: 0.208392\tvalid_1's MacroF1Metric: 0.919957\n",
      "[300]\ttraining's rmse: 0.162254\ttraining's MacroF1Metric: 0.935004\tvalid_1's rmse: 0.163207\tvalid_1's MacroF1Metric: 0.935206\n",
      "[400]\ttraining's rmse: 0.158379\ttraining's MacroF1Metric: 0.936386\tvalid_1's rmse: 0.159656\tvalid_1's MacroF1Metric: 0.936236\n",
      "[500]\ttraining's rmse: 0.157364\ttraining's MacroF1Metric: 0.936932\tvalid_1's rmse: 0.158906\tvalid_1's MacroF1Metric: 0.936724\n",
      "[600]\ttraining's rmse: 0.156763\ttraining's MacroF1Metric: 0.93738\tvalid_1's rmse: 0.158539\tvalid_1's MacroF1Metric: 0.936985\n",
      "[700]\ttraining's rmse: 0.156328\ttraining's MacroF1Metric: 0.93765\tvalid_1's rmse: 0.158314\tvalid_1's MacroF1Metric: 0.937201\n",
      "[800]\ttraining's rmse: 0.155964\ttraining's MacroF1Metric: 0.937878\tvalid_1's rmse: 0.158141\tvalid_1's MacroF1Metric: 0.937325\n",
      "[900]\ttraining's rmse: 0.155653\ttraining's MacroF1Metric: 0.938079\tvalid_1's rmse: 0.158011\tvalid_1's MacroF1Metric: 0.93746\n",
      "[1000]\ttraining's rmse: 0.155346\ttraining's MacroF1Metric: 0.938257\tvalid_1's rmse: 0.157881\tvalid_1's MacroF1Metric: 0.93746\n",
      "[1100]\ttraining's rmse: 0.155068\ttraining's MacroF1Metric: 0.938418\tvalid_1's rmse: 0.157781\tvalid_1's MacroF1Metric: 0.93748\n",
      "[1200]\ttraining's rmse: 0.15482\ttraining's MacroF1Metric: 0.938593\tvalid_1's rmse: 0.157704\tvalid_1's MacroF1Metric: 0.937512\n",
      "[1300]\ttraining's rmse: 0.154566\ttraining's MacroF1Metric: 0.938715\tvalid_1's rmse: 0.157621\tvalid_1's MacroF1Metric: 0.937557\n",
      "[1400]\ttraining's rmse: 0.154321\ttraining's MacroF1Metric: 0.938874\tvalid_1's rmse: 0.157547\tvalid_1's MacroF1Metric: 0.937614\n",
      "[1500]\ttraining's rmse: 0.154091\ttraining's MacroF1Metric: 0.939004\tvalid_1's rmse: 0.157485\tvalid_1's MacroF1Metric: 0.937649\n",
      "[1600]\ttraining's rmse: 0.153866\ttraining's MacroF1Metric: 0.939194\tvalid_1's rmse: 0.157427\tvalid_1's MacroF1Metric: 0.937639\n",
      "[1700]\ttraining's rmse: 0.153649\ttraining's MacroF1Metric: 0.939345\tvalid_1's rmse: 0.157374\tvalid_1's MacroF1Metric: 0.937637\n",
      "Early stopping, best iteration is:\n",
      "[1586]\ttraining's rmse: 0.153898\ttraining's MacroF1Metric: 0.939131\tvalid_1's rmse: 0.157435\tvalid_1's MacroF1Metric: 0.937664\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.610723\ttraining's MacroF1Metric: 0.340309\tvalid_1's rmse: 0.610705\tvalid_1's MacroF1Metric: 0.340261\n",
      "[200]\ttraining's rmse: 0.207907\ttraining's MacroF1Metric: 0.920104\tvalid_1's rmse: 0.208547\tvalid_1's MacroF1Metric: 0.91967\n",
      "[300]\ttraining's rmse: 0.162314\ttraining's MacroF1Metric: 0.935114\tvalid_1's rmse: 0.163542\tvalid_1's MacroF1Metric: 0.933965\n",
      "[400]\ttraining's rmse: 0.158384\ttraining's MacroF1Metric: 0.936628\tvalid_1's rmse: 0.159951\tvalid_1's MacroF1Metric: 0.935634\n",
      "[500]\ttraining's rmse: 0.157388\ttraining's MacroF1Metric: 0.93724\tvalid_1's rmse: 0.15921\tvalid_1's MacroF1Metric: 0.936086\n",
      "[600]\ttraining's rmse: 0.156767\ttraining's MacroF1Metric: 0.93761\tvalid_1's rmse: 0.158795\tvalid_1's MacroF1Metric: 0.936423\n",
      "[700]\ttraining's rmse: 0.15633\ttraining's MacroF1Metric: 0.937929\tvalid_1's rmse: 0.158574\tvalid_1's MacroF1Metric: 0.936446\n",
      "[800]\ttraining's rmse: 0.155974\ttraining's MacroF1Metric: 0.938102\tvalid_1's rmse: 0.158407\tvalid_1's MacroF1Metric: 0.936479\n",
      "[900]\ttraining's rmse: 0.155651\ttraining's MacroF1Metric: 0.938271\tvalid_1's rmse: 0.158258\tvalid_1's MacroF1Metric: 0.936616\n",
      "[1000]\ttraining's rmse: 0.155353\ttraining's MacroF1Metric: 0.938412\tvalid_1's rmse: 0.158124\tvalid_1's MacroF1Metric: 0.936671\n",
      "[1100]\ttraining's rmse: 0.155069\ttraining's MacroF1Metric: 0.938537\tvalid_1's rmse: 0.158012\tvalid_1's MacroF1Metric: 0.936678\n",
      "[1200]\ttraining's rmse: 0.154787\ttraining's MacroF1Metric: 0.938702\tvalid_1's rmse: 0.157897\tvalid_1's MacroF1Metric: 0.936745\n",
      "[1300]\ttraining's rmse: 0.154523\ttraining's MacroF1Metric: 0.938868\tvalid_1's rmse: 0.157807\tvalid_1's MacroF1Metric: 0.936857\n",
      "[1400]\ttraining's rmse: 0.154273\ttraining's MacroF1Metric: 0.939018\tvalid_1's rmse: 0.157727\tvalid_1's MacroF1Metric: 0.936926\n",
      "[1500]\ttraining's rmse: 0.154033\ttraining's MacroF1Metric: 0.939179\tvalid_1's rmse: 0.157654\tvalid_1's MacroF1Metric: 0.93698\n",
      "[1600]\ttraining's rmse: 0.153806\ttraining's MacroF1Metric: 0.939345\tvalid_1's rmse: 0.157585\tvalid_1's MacroF1Metric: 0.937039\n",
      "[1700]\ttraining's rmse: 0.153598\ttraining's MacroF1Metric: 0.939478\tvalid_1's rmse: 0.157538\tvalid_1's MacroF1Metric: 0.937067\n",
      "[1800]\ttraining's rmse: 0.153391\ttraining's MacroF1Metric: 0.939655\tvalid_1's rmse: 0.157488\tvalid_1's MacroF1Metric: 0.93704\n",
      "[1900]\ttraining's rmse: 0.153182\ttraining's MacroF1Metric: 0.939785\tvalid_1's rmse: 0.157441\tvalid_1's MacroF1Metric: 0.93708\n",
      "[2000]\ttraining's rmse: 0.152978\ttraining's MacroF1Metric: 0.939934\tvalid_1's rmse: 0.157397\tvalid_1's MacroF1Metric: 0.937093\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.152978\ttraining's MacroF1Metric: 0.939934\tvalid_1's rmse: 0.157397\tvalid_1's MacroF1Metric: 0.937093\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.610741\ttraining's MacroF1Metric: 0.340022\tvalid_1's rmse: 0.610858\tvalid_1's MacroF1Metric: 0.339955\n",
      "[200]\ttraining's rmse: 0.207855\ttraining's MacroF1Metric: 0.920184\tvalid_1's rmse: 0.208356\tvalid_1's MacroF1Metric: 0.919814\n",
      "[300]\ttraining's rmse: 0.162221\ttraining's MacroF1Metric: 0.935151\tvalid_1's rmse: 0.163186\tvalid_1's MacroF1Metric: 0.934399\n",
      "[400]\ttraining's rmse: 0.158366\ttraining's MacroF1Metric: 0.936636\tvalid_1's rmse: 0.159699\tvalid_1's MacroF1Metric: 0.935873\n",
      "[500]\ttraining's rmse: 0.157321\ttraining's MacroF1Metric: 0.937226\tvalid_1's rmse: 0.15896\tvalid_1's MacroF1Metric: 0.936288\n",
      "[600]\ttraining's rmse: 0.156738\ttraining's MacroF1Metric: 0.937628\tvalid_1's rmse: 0.158601\tvalid_1's MacroF1Metric: 0.936609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttraining's rmse: 0.156289\ttraining's MacroF1Metric: 0.937886\tvalid_1's rmse: 0.158369\tvalid_1's MacroF1Metric: 0.936758\n",
      "[800]\ttraining's rmse: 0.155928\ttraining's MacroF1Metric: 0.938088\tvalid_1's rmse: 0.158207\tvalid_1's MacroF1Metric: 0.936957\n",
      "[900]\ttraining's rmse: 0.155639\ttraining's MacroF1Metric: 0.938214\tvalid_1's rmse: 0.158104\tvalid_1's MacroF1Metric: 0.937012\n",
      "[1000]\ttraining's rmse: 0.155351\ttraining's MacroF1Metric: 0.938389\tvalid_1's rmse: 0.158001\tvalid_1's MacroF1Metric: 0.937035\n",
      "[1100]\ttraining's rmse: 0.155073\ttraining's MacroF1Metric: 0.938559\tvalid_1's rmse: 0.157904\tvalid_1's MacroF1Metric: 0.937086\n",
      "[1200]\ttraining's rmse: 0.154794\ttraining's MacroF1Metric: 0.93872\tvalid_1's rmse: 0.157801\tvalid_1's MacroF1Metric: 0.937091\n",
      "[1300]\ttraining's rmse: 0.15453\ttraining's MacroF1Metric: 0.938891\tvalid_1's rmse: 0.157702\tvalid_1's MacroF1Metric: 0.937164\n",
      "[1400]\ttraining's rmse: 0.154276\ttraining's MacroF1Metric: 0.939027\tvalid_1's rmse: 0.157622\tvalid_1's MacroF1Metric: 0.937209\n",
      "[1500]\ttraining's rmse: 0.154049\ttraining's MacroF1Metric: 0.939195\tvalid_1's rmse: 0.157561\tvalid_1's MacroF1Metric: 0.937303\n",
      "[1600]\ttraining's rmse: 0.153813\ttraining's MacroF1Metric: 0.939346\tvalid_1's rmse: 0.157498\tvalid_1's MacroF1Metric: 0.937334\n",
      "[1700]\ttraining's rmse: 0.153604\ttraining's MacroF1Metric: 0.939472\tvalid_1's rmse: 0.157451\tvalid_1's MacroF1Metric: 0.937371\n",
      "[1800]\ttraining's rmse: 0.15339\ttraining's MacroF1Metric: 0.939591\tvalid_1's rmse: 0.157404\tvalid_1's MacroF1Metric: 0.937318\n",
      "Early stopping, best iteration is:\n",
      "[1678]\ttraining's rmse: 0.153655\ttraining's MacroF1Metric: 0.939443\tvalid_1's rmse: 0.157465\tvalid_1's MacroF1Metric: 0.937379\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's rmse: 0.610716\ttraining's MacroF1Metric: 0.340346\tvalid_1's rmse: 0.611025\tvalid_1's MacroF1Metric: 0.340015\n",
      "[200]\ttraining's rmse: 0.207908\ttraining's MacroF1Metric: 0.920236\tvalid_1's rmse: 0.208613\tvalid_1's MacroF1Metric: 0.920117\n",
      "[300]\ttraining's rmse: 0.162281\ttraining's MacroF1Metric: 0.935164\tvalid_1's rmse: 0.163307\tvalid_1's MacroF1Metric: 0.934362\n",
      "[400]\ttraining's rmse: 0.15839\ttraining's MacroF1Metric: 0.936733\tvalid_1's rmse: 0.159718\tvalid_1's MacroF1Metric: 0.935685\n",
      "[500]\ttraining's rmse: 0.157376\ttraining's MacroF1Metric: 0.937256\tvalid_1's rmse: 0.158973\tvalid_1's MacroF1Metric: 0.936005\n",
      "[600]\ttraining's rmse: 0.156786\ttraining's MacroF1Metric: 0.937692\tvalid_1's rmse: 0.158602\tvalid_1's MacroF1Metric: 0.936406\n",
      "[700]\ttraining's rmse: 0.15634\ttraining's MacroF1Metric: 0.937943\tvalid_1's rmse: 0.158392\tvalid_1's MacroF1Metric: 0.936596\n",
      "[800]\ttraining's rmse: 0.155994\ttraining's MacroF1Metric: 0.938101\tvalid_1's rmse: 0.158248\tvalid_1's MacroF1Metric: 0.936724\n",
      "[900]\ttraining's rmse: 0.155684\ttraining's MacroF1Metric: 0.938242\tvalid_1's rmse: 0.158123\tvalid_1's MacroF1Metric: 0.936836\n",
      "[1000]\ttraining's rmse: 0.155398\ttraining's MacroF1Metric: 0.9384\tvalid_1's rmse: 0.158018\tvalid_1's MacroF1Metric: 0.936832\n",
      "[1100]\ttraining's rmse: 0.155117\ttraining's MacroF1Metric: 0.938542\tvalid_1's rmse: 0.157922\tvalid_1's MacroF1Metric: 0.936888\n",
      "[1200]\ttraining's rmse: 0.154855\ttraining's MacroF1Metric: 0.938689\tvalid_1's rmse: 0.15784\tvalid_1's MacroF1Metric: 0.936906\n",
      "[1300]\ttraining's rmse: 0.154603\ttraining's MacroF1Metric: 0.938822\tvalid_1's rmse: 0.157758\tvalid_1's MacroF1Metric: 0.93701\n",
      "[1400]\ttraining's rmse: 0.154364\ttraining's MacroF1Metric: 0.938958\tvalid_1's rmse: 0.157691\tvalid_1's MacroF1Metric: 0.937054\n",
      "[1500]\ttraining's rmse: 0.154112\ttraining's MacroF1Metric: 0.939108\tvalid_1's rmse: 0.157605\tvalid_1's MacroF1Metric: 0.937084\n",
      "[1600]\ttraining's rmse: 0.153884\ttraining's MacroF1Metric: 0.939247\tvalid_1's rmse: 0.157535\tvalid_1's MacroF1Metric: 0.937117\n",
      "[1700]\ttraining's rmse: 0.153648\ttraining's MacroF1Metric: 0.939417\tvalid_1's rmse: 0.157468\tvalid_1's MacroF1Metric: 0.937107\n",
      "Early stopping, best iteration is:\n",
      "[1637]\ttraining's rmse: 0.153794\ttraining's MacroF1Metric: 0.939326\tvalid_1's rmse: 0.15751\tvalid_1's MacroF1Metric: 0.937161\n",
      "\n",
      "Mean oof f1:0.9373597158725063, std: 0.00021166700562072648\n"
     ]
    }
   ],
   "source": [
    "oof_df_lgb, feat_importance_df_lgb, sub_lgb2, oof_f2, oof_rmse2 = train_lgb(\n",
    "    params=params_lgb,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    X_test=X_test,\n",
    "    early_stopping_rounds=150,\n",
    "    num_boost_round=2000,  # 3000\n",
    "    oof_df=oof_df,\n",
    "    features=features,\n",
    "    feval=feval,\n",
    "    verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lgb2['open_channels'] = sub_lgb2.iloc[:, 2:].median(axis=1).astype(int)\n",
    "\n",
    "sub_lgb2[['time', 'open_channels']].to_csv('submission_lgb_with_drift_rolling.csv', \n",
    "                                           index=False,\n",
    "                                           float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 21.0M/21.0M [00:10<00:00, 2.19MB/s]\n",
      "Successfully submitted to University of Liverpool - Ion Switching"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c liverpool-ion-switching -f submission_lgb_with_drift_rolling.csv -m \"with drift removed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df_lgb.to_csv('oof_df_lgb_undrifted_rolling.csv', index=False)\n",
    "feat_importance_df_lgb.to_csv('feat_importance_df_lgb_undrifted_rolling.csv', index=False)\n",
    "sub_lgb2.to_csv('sub_lgb_with_folds_undrifted_rolling.csv', index=False, float_format='%.4f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lgb2 = pd.read_csv('sub_lgb_with_folds_undrifted_rolling.csv')\n",
    "sub_lgb2['open_channels'] = np.round(np.clip(sub_lgb2.iloc[:, 2:].mean(axis=1).values, 0, 10)).astype(np.int32)\n",
    "\n",
    "sub_lgb2[['time', 'open_channels']].to_csv('submission_lgb_with_drift_rolling_mean.csv', \n",
    "                                           index=False,\n",
    "                                           float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 21.0M/21.0M [00:08<00:00, 2.50MB/s]\n",
      "Successfully submitted to University of Liverpool - Ion Switching"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c liverpool-ion-switching -f submission_lgb_with_drift_rolling_mean.csv -m \"with drift removed and mean\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    'colsample_bytree': 0.375,\n",
    "    'learning_rate': 0.09,\n",
    "    'max_depth': 8,\n",
    "    'seed': 42,\n",
    "    'eval_metric': 'rmse',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'reg_lambda': 1, # these are default\n",
    "    'reg_alpha': 0 # these are default\n",
    "}\n",
    "def MacroF1MetricRegressionXGB(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = np.round(np.clip(preds, 0, 10)).astype(np.int16)\n",
    "    score = f1_score(labels, preds, average='macro')\n",
    "    return ('MacroF1MetricXGB', score)\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "X = train[features]\n",
    "X_test = test[features]\n",
    "y = train['open_channels']\n",
    "oof_df = train[['time', 'open_channels']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df_xgb, feat_importance_df_xgb, sub_xgb, oof_f1, oof_rmse = train_xgb(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    X_test=X_test,\n",
    "    verbose_eval=100,\n",
    "    oof_df=oof_df,\n",
    "    features=features,\n",
    "    params=params_xgb,\n",
    "    feval={'regression':MacroF1MetricRegressionXGB},\n",
    "    objective='regression',\n",
    "    num_boost_round=3000,\n",
    "    early_stopping_rounds=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PyTorch` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cols = [s for s in sub.columns if 'open_channels' in s]\n",
    "\n",
    "sub['open_channels'] = sub[s_cols].median(axis=1).astype(int)\n",
    "\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
